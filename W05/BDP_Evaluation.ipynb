{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Processes Exercises - Week 05\n",
    "# <font color= Pink>Evaluation</font>\n",
    "\n",
    "#### What we will cover today\n",
    "\n",
    "<ol>\n",
    "    <li>Importing packages and libraries</li>\n",
    "    <li>Loading the dataset</li>\n",
    "    <li>Selecting target features</li>\n",
    "    <li>Splitting the data</li>\n",
    "    <li>1st Modeling</li>\n",
    "    <li>Evaluation</li>\n",
    "    <ol>\n",
    "        <li>Confusion Matrix</li>\n",
    "        <li>Scores & Metrics</li>\n",
    "    </ol>\n",
    "    <li>Oversampling</li>\n",
    "    <ol>\n",
    "        <li>Random Oversampling</li>\n",
    "        <li>SMOTE</li>\n",
    "    </ol>\n",
    "    <li>Undersamling</li>\n",
    "    <ol>\n",
    "        <li>Random Undersampling</li>\n",
    "        <li>TomekLinks</li>\n",
    "    </ol>\n",
    "    <li>Combination of over- & undersampling</li>\n",
    "    <ol>\n",
    "        <li>SMOTE & TomekLinks</li>\n",
    "    </ol>\n",
    "    <li>Evaluation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Evaluation Metrics - look up\n",
    "A 'quick' recap from Bruce & Bruce and [machinelearningmastery.com](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python//):\n",
    "\n",
    "**<font color= Orchid>Accuracy</font>**<br>\n",
    "The percent (or proportion) of cases classified correctly. Being the most common evaluation metric for classification problems, it is also the most misused. It is really only suitable when there are an equal number of observations in each class. Why is this? Think of a dataset on sunny days in Hawaii. The distribution of sunny vs. not-sunny days would probably be quite unbalanced (e.g., 95% sunny days and 5% not-sunny days). A classifier model trying to predict whether a day will be sunny could receive a very high accuracy by simply always predicting the biggest class (sunny). As such, the accuracy metric does not reflect the model's ability to correctly classificy the smallest class (not-sunny days).\n",
    "\n",
    "Furthermore, the accuracy metric 'assumes' that all predictions and prediction errors are equally important. What do we mean by this? Imagine that we are trying to predict a medical condition. Here, we might have a model which is overall pretty accurate. However, when we take a closer look at the model, we see that there is a lot of 'false negatives' (i.e., patients being misclassified as healthy although they actually have the diagnosis). This misclassification is much more critical than a 'false positive' (i.e., a patient being classified as having the condition, although they are healthy). The accuracy metric itself does not account for this, but treats all false predictions equally. However, as the example shows, certain types of errors might be more costly or harmful than others. The metrics below are ways to address the limitations of the accuracy metric.\n",
    "\n",
    "**<font color= Orchid>Confusion matrix</font>**<br>\n",
    "A tabular display (2×2 in the binary case) of the record counts by their predicted and actual classification status. In other words, it shows the amount of true positive and true negative predictions as well as false positive and false negative predictions made by the model. What does these terms mean? Think of our IBM classification model predicting attrition (i.e. whether an employee will leave the company). In this dataset, the value '1' means 'true' = the employee did leave the company, while the value '0' means 'false' = the employee did not leave the company:\n",
    "- We say a prediction is a *<font color= Orchid>true positive</font>* when the model predicts '1' and the correct class is indeed '1' (the employee actually left the company). \n",
    "- We say a prediction is a *<font color= Orchid>true negative</font>*, when the model predicts '0' and the correct class is indeed '0' (the employee did not leave). \n",
    "- Similarly, a *<font color= Orchid>false positive</font>* prediction is when the model predicts '1', when the correct class is actually '0' (i.e., the employee is predicted to have left the company, but in fact did not leave). \n",
    "- A *<font color= Orchid>false negative</font>* prediction is when the model predicts '0', when the correct class is actually '1' (i.e., the employee is predicted to stay, but in fact left the comapny).\n",
    "\n",
    "**<font color= Orchid>Recall</font>** - minimizing false negatives <br>\n",
    "This metric is also called sensitivity or 'true positive rate'. It signifies the percent (or proportion) of all '1's that are correctly classified as '1's. In other words, it answers the question: <font color= Orchid>*\"Of all the instances in the test data that belong to '1', how many did the model correctly predict as '1'?\"</font>*. In the case of the IBM dataset, we take all the employees that left the company and calculate how many the model predicted correctly as having left the company.\n",
    "\n",
    "Recall is particularly useful in situations where the cost of missing a positive instance (i.e., making a false negative prediction) is high. For example, in medical diagnostics, as described above, recall tells us the percentage of all actual patients with the disease that the model correctly identifies as having the disease. Thus, a high recall means the model is effectively identifying a large portion of patients with a certain condition, minimizing the number of cases where the condition goes undetected. We can optimize our models for high recall, which means that we focus on minimizing false negatives. However, we must be mindful that this may come at the expense of precision (see below), as the model may classify more instances as positive, including some that are actually negative. In other words, a model with high recall may classify more patients as having the condition when they are in fact healthy. \n",
    "\n",
    "**<font color= Orchid>Precision</font>** - minimizing false positives <br>\n",
    "The percent (proportion) of true positives (instances predicted as '1', which are in fact '1') out of all the positive predictions made by the model. It answers the question: *<font color= Orchid>\"Of all the instances in the test data predicted as '1' by the model, how many in this group are in fact '1'?\"*</font>. In the case of the IBM dataset, we take all the employees that was predicted to have left the company and assess how many of these in fact left.\n",
    "\n",
    "Precision helps us to assess whether the positive predictions made by our model are accurate. High precision indicates that the model makes fewer false positive predictions, minimizing the number of instances incorrectly classified as positive. It is important in situations where false positives have high costs or consequences.\n",
    "\n",
    "**<font color= Orchid>Recall vs. Precision</font>**<br>\n",
    "In recall, we first *<font color= Orchid>group together all the positive instances</font>* in our test dataset and then, we figure out how many of these have been correctly predicted as positive by our model. (Recall: How many of the positive items were identified correctly?)\n",
    "<br>\n",
    "In precision, we first *<font color= Orchid>group together all the instances that our model predicted to be positive</font>* and then, we figure out how many of these were in fact positive. (Precision: How many of the items predicted to be positive are actually positive?)\n",
    "\n",
    "\n",
    "**<font color= Orchid>Specificity</font>* <br>\n",
    "The percent (or proportion) of all 0s that are correctly classified as 0s. It measures the ability of a model to correctly identify negative instances (true negatives) out of all actual negative instances.  In other words, specificity answers the question: *<font color= Orchid>\"Of all the instances that truly belong to the negative class, how many did the model correctly predict as negative?\"</font>*. While recall measures the model's ability to identify positive instances, specificity complements this by measuring the model's ability to identify negative instances. A high specificity value indicates that the model is good at avoiding false positives and accurately classifying negative instances. Conversely, a low specificity value suggests that the model is incorrectly classifying negative instances as positive, leading to false alarms. To return to our medical example, if specificity is high, it means the model is good at correctly identifying healthy patients as healthy, minimizing the number of healthy patients mistakenly classified as having a disease.\n",
    "\n",
    "**<font color= Orchid>Area Under ROC curve</font>** <br>\n",
    "Is also called AUC-ROC for short. The AUC-ROC score ranges from 0 to 1 where:\n",
    "- AUC-ROC = 1 indicates a perfect classifier that achieves perfect separation between positive and negative instances.\n",
    "- AUC-ROC = 0.5 indicates a classifier that performs no better than random guessing.\n",
    "- AUC-ROC < 0.5 indicates a classifier that performs worse than random guessing.\n",
    "\n",
    "In other words, it's a number that tells you how well your model can separate positive cases from negative cases overall. The higher the AUC-ROC, the better the model is at this task. If the AUC-ROC is 1, it means the model is perfect. If it's 0.5, it's no better than flipping a coin.\n",
    "It is a great performance metric for binary classification problems.\n",
    "\n",
    "Below, the ROC curve is pictured. The AUC-ROC is like a summary score for this graph.\n",
    "\n",
    "<img src=\"roc.jpg\" width=\"500\"/>\n",
    "\n",
    "**<font color= Orchid>F1 curve</font>** <br>\n",
    "The F1 score is a single metric that combines both precision and recall into one value, providing a balanced measure of a model's performance, especially in situations where there is an imbalance between the classes. In words, the F1 score is the harmonic mean of precision and recall. The harmonic mean gives more weight to low values. This means that the F1 score will be high only if both precision and recall are high.\n",
    "\n",
    "***\n",
    "***\n",
    "*** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Importing various packages and libraries\n",
    "\n",
    "Install the imblearn library if you don't have it yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imblearn) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/simonskodt/anaconda3/envs/iml/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#Sampling libraries\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 2. Loading dataset and examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will again be using the **IBM-employee-attrition dataset** where we will try and predict if an employee has attrition or not, aka. whether they have left the company or not. \n",
    "\n",
    "As we have explained before, our target variable, attrition, is either be 0 or 1:\n",
    "- 0 = No attrition, the employee did not leave the company\n",
    "- 1 = Attrition, the employee left the company\n",
    "\n",
    "Let's load the dataset into our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMB-Employee-Attrition.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the same dataset as last week, but feel free to explore it yet again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   int64 \n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(27), object(8)\n",
      "memory usage: 402.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.923810</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>802.485714</td>\n",
       "      <td>9.192517</td>\n",
       "      <td>2.912925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024.865306</td>\n",
       "      <td>2.721769</td>\n",
       "      <td>65.891156</td>\n",
       "      <td>2.729932</td>\n",
       "      <td>...</td>\n",
       "      <td>2.712245</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>11.279592</td>\n",
       "      <td>2.799320</td>\n",
       "      <td>2.761224</td>\n",
       "      <td>7.008163</td>\n",
       "      <td>4.229252</td>\n",
       "      <td>2.187755</td>\n",
       "      <td>4.123129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.135373</td>\n",
       "      <td>0.367863</td>\n",
       "      <td>403.509100</td>\n",
       "      <td>8.106864</td>\n",
       "      <td>1.024165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602.024335</td>\n",
       "      <td>1.093082</td>\n",
       "      <td>20.329428</td>\n",
       "      <td>0.711561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>7.780782</td>\n",
       "      <td>1.289271</td>\n",
       "      <td>0.706476</td>\n",
       "      <td>6.126525</td>\n",
       "      <td>3.623137</td>\n",
       "      <td>3.222430</td>\n",
       "      <td>3.568136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>491.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1157.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1555.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>83.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2068.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age    Attrition    DailyRate  DistanceFromHome    Education  \\\n",
       "count  1470.000000  1470.000000  1470.000000       1470.000000  1470.000000   \n",
       "mean     36.923810     0.161224   802.485714          9.192517     2.912925   \n",
       "std       9.135373     0.367863   403.509100          8.106864     1.024165   \n",
       "min      18.000000     0.000000   102.000000          1.000000     1.000000   \n",
       "25%      30.000000     0.000000   465.000000          2.000000     2.000000   \n",
       "50%      36.000000     0.000000   802.000000          7.000000     3.000000   \n",
       "75%      43.000000     0.000000  1157.000000         14.000000     4.000000   \n",
       "max      60.000000     1.000000  1499.000000         29.000000     5.000000   \n",
       "\n",
       "       EmployeeCount  EmployeeNumber  EnvironmentSatisfaction   HourlyRate  \\\n",
       "count         1470.0     1470.000000              1470.000000  1470.000000   \n",
       "mean             1.0     1024.865306                 2.721769    65.891156   \n",
       "std              0.0      602.024335                 1.093082    20.329428   \n",
       "min              1.0        1.000000                 1.000000    30.000000   \n",
       "25%              1.0      491.250000                 2.000000    48.000000   \n",
       "50%              1.0     1020.500000                 3.000000    66.000000   \n",
       "75%              1.0     1555.750000                 4.000000    83.750000   \n",
       "max              1.0     2068.000000                 4.000000   100.000000   \n",
       "\n",
       "       JobInvolvement  ...  RelationshipSatisfaction  StandardHours  \\\n",
       "count     1470.000000  ...               1470.000000         1470.0   \n",
       "mean         2.729932  ...                  2.712245           80.0   \n",
       "std          0.711561  ...                  1.081209            0.0   \n",
       "min          1.000000  ...                  1.000000           80.0   \n",
       "25%          2.000000  ...                  2.000000           80.0   \n",
       "50%          3.000000  ...                  3.000000           80.0   \n",
       "75%          3.000000  ...                  4.000000           80.0   \n",
       "max          4.000000  ...                  4.000000           80.0   \n",
       "\n",
       "       StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "count       1470.000000        1470.000000            1470.000000   \n",
       "mean           0.793878          11.279592               2.799320   \n",
       "std            0.852077           7.780782               1.289271   \n",
       "min            0.000000           0.000000               0.000000   \n",
       "25%            0.000000           6.000000               2.000000   \n",
       "50%            1.000000          10.000000               3.000000   \n",
       "75%            1.000000          15.000000               3.000000   \n",
       "max            3.000000          40.000000               6.000000   \n",
       "\n",
       "       WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "count      1470.000000     1470.000000         1470.000000   \n",
       "mean          2.761224        7.008163            4.229252   \n",
       "std           0.706476        6.126525            3.623137   \n",
       "min           1.000000        0.000000            0.000000   \n",
       "25%           2.000000        3.000000            2.000000   \n",
       "50%           3.000000        5.000000            3.000000   \n",
       "75%           3.000000        9.000000            7.000000   \n",
       "max           4.000000       40.000000           18.000000   \n",
       "\n",
       "       YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "count              1470.000000           1470.000000  \n",
       "mean                  2.187755              4.123129  \n",
       "std                   3.222430              3.568136  \n",
       "min                   0.000000              0.000000  \n",
       "25%                   0.000000              2.000000  \n",
       "50%                   1.000000              3.000000  \n",
       "75%                   3.000000              7.000000  \n",
       "max                  15.000000             17.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 3. Selecting target features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select the same features as we've used before for our models (go back to the notebook for week 3, if you need a refresher as to how we got these features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the feature and target variables\n",
    "#From list of feature(s) 'X', the model will guess/predict the 'y' feature (our target)\n",
    "X = df[['EnvironmentSatisfaction', 'JobSatisfaction', 'JobInvolvement', 'YearsAtCompany', 'StockOptionLevel', 'YearsWithCurrManager', 'Age', 'MonthlyIncome', 'YearsInCurrentRole', 'JobLevel', 'TotalWorkingYears']].values\n",
    "\n",
    "y = df['Attrition'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 4. Splitting the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data as usual, such that we have some data to train the model, and some data to test the accuracy of our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train - 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## 5. 1st Modelling - Ordinary Decision Tree with no sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classificer _ No Sampling\n",
    "DTC_ns = DecisionTreeClassifier(criterion=\"gini\", max_depth=6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC_ns.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_ns_pred = DTC_ns.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8469387755102041\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, DTC_ns_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 249\n",
      "Incorrect predictions: 45\n",
      "Total predictions: 294\n"
     ]
    }
   ],
   "source": [
    "mtr = confusion_matrix(y_test, DTC_ns_pred)\n",
    "\n",
    "print(\"Correct predictions:\", (mtr[0,0] + mtr[1,1]))\n",
    "print(\"Incorrect predictions:\", (mtr[0,1] + mtr[1,0]))\n",
    "print(\"Total predictions:\", (mtr.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our decision tree classifier with a max depth of 6 has an accuracy of ~85%. However, as noted in the beginning, the accuracy score alone is not enough to truly evaluate the performance of a model. So, now, let us evaluate this model utilizing our new metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 6. Evaluation\n",
    "\n",
    "In this section, we will be focusing on:\n",
    "- Accuracy score\n",
    "- Confusion matrix\n",
    "- AUC-RUC\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "If you are unsure of what these metrics are, go back to the introductory section of this notebook, where we define the terms.\n",
    "\n",
    "**Accuracy** is calculated by the number of correct predictions divided by the total number of predictions, so:\n",
    "\n",
    "<font color=Orchid> Accuracy = Correct Predictions / Total Predictions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8469387755102041\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, DTC_ns_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see  that our model is doing pretty good with ~85% accuracy. But a problem with accuracy within classification is that it hides a lot of the details, which you need know, to better understand the performance of your model. \n",
    "\n",
    "When your data has two or more classes to predict, the accuracy score will never know if the classes are being predicted equally well or whether one or two classes are being neglected by the model based on accuracy.\n",
    "\n",
    "Let us take a look at the class distribution in the IBM dataset, when it comes to Attrition:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attrition\n",
       "0    1233\n",
       "1     237\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Attrition']).Attrition.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 237 of employees (19%) in the dataset left the company. \n",
    "\n",
    "**237 ÷ 1233 = 0.1922 = 19.22%**\n",
    "\n",
    "This means that we are working with an imbalanced dataset. Therefore we cannot use accuracy as a good performance metric. Because our model learned on our training data that there are more 'No  Attrition' instances than 'Attrition' instances, it will always rather predict 'No Attrition', since there is a better chance it will be correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Confusion matrix\n",
    "\n",
    "Since we have now found out that accuracy score alone is not a good metric for the IBM dataset, we will use a confusion matrix to further evaluate our model. As you may recall, the confusion matrix shows the amount of true positive and true negative predictions as well as the amount of false positive and false negative predictions made by the model.\n",
    "\n",
    "The confusion matrix is the basis for many of the evaluation matricies. It provides more insight into not only the performance of the model but also which classes are being predicted correctly, which incorrectly, and what type of errors are being made.\n",
    "\n",
    "Now, let's make a confusion matrix!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the Decision Tree Classifier with No Sampling on test set: \n",
      "\n",
      " [[245  10]\n",
      " [ 35   4]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, DTC_ns_pred)\n",
    "\n",
    "print(\"Confusion matrix for the Decision Tree Classifier with No Sampling on test set: \\n\\n\", cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix with ✨ visualisation ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_names = ['True Negative','False Positive','False Negative','True Posistive']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **True positive** for correctly predicted target values (correctly predicted 'Attrition')\n",
    "- **False positive** for incorrectly predicted target values (incorrectly predicted 'Attrition')\n",
    "- **True negative** for correctly predicted no-event values (correctly predicted 'No Attrition')\n",
    "- **False negative** for incorrectly predicted no-event values (incorrectly predicted 'No Attrition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=turquoise>EXERCISE 1</font>**\n",
    "Explain what you can conclude from the confusion matrix visualized above. What does the confusion matrix tell you about the model, that you couldn't see from the accuracy score alone? \n",
    "\n",
    "Also, imagine our model was classifiying patients according to whether they had a diagnosis of some sort. How many patients would have been classified as healthy although they actually had the condition and needed treatment?b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 1px; background-color: white;\">\n",
    "    <p style=\"color: black; text-align: center\"><b>ANSWER</b></p>\n",
    "</div>\n",
    "\n",
    "**Type in your answers here:**\n",
    "\n",
    "We can see that the actual number of employees who left IBM is 237 (where attrition is 1).\n",
    "\n",
    "- True negative: There were 245 employees that we correctly predicted 'no attrition'.\n",
    "- False positive: There were 10 employees that we predicted to leave the company, but who actually did not leave (no attrition).\n",
    "- False negative: There were 35 employees that we predicted to stay at the company (no attrition), but who actually left the company.\n",
    "- True positive: There were 4 employees that we correctly predicted as 'attrition'.\n",
    "\n",
    "The confusion matrix tells us how many employees we incorrectly predicted and whether it was a false positive or a false negative. This information cannot be obtained from the accuracy score alone.\n",
    "\n",
    "When classifying patients for a diagnosis, it is generally more acceptable to have a higher number of false positives (predicting a patient has the condition when they don't) than false negatives (predicting a patient doesn't have the condition when they actually do). This is because it is better to be cautious and recommend further testing or treatment for a patient who may not have the condition, rather than missing a diagnosis and not providing necessary treatment.\n",
    "\n",
    "<div style=\"width: 100%; height: 1px; background-color: white;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Scores & Metrics\n",
    "\n",
    "From the confusion  matrix we can calculate other scores that we can use as our metrics.\n",
    "\n",
    "- **Precision**. Calculated by: <font color=Orchid> TruePositive / (TruePositive + FalsePositive)  </font>\n",
    "- **Recall**. Calculated by: <font color=Orchid> TruePositive / (TruePositive + FalseNegative)</font>\n",
    "- **F1 Score**. Calculated by: <font color=Orchid>(2 * Precision * Recall) / (Precision + Recall)</font>\n",
    "- **ROC-AUC**. ROC plots the True Positive rate (TPR) against the False Positive rate (FPR). The ROC-AUC (area under the ROC curve)  then sums up how well a model can produce relative scores to discriminate between positive or negative instances across all classification thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2857142857142857\n",
      "Recall: 0.10256410256410256\n",
      "F1-Score: 0.1509433962264151\n",
      "AUC-ROC: 0.5316742081447964\n"
     ]
    }
   ],
   "source": [
    "# Precision \n",
    "precision = precision_score(y_test, DTC_ns_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_ns_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_ns_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_ns_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    " \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"AUC-ROC:\", roc_auc) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=turquoise>EXERCISE 2</font>**\n",
    "Revisit the explanations in the introduction of this notebook (or look up the metrics on the internet). Then explain what each of these values tells us about the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 1px; background-color: white;\">\n",
    "    <p style=\"color: black; text-align: center\"><b>ANSWER</b></p>\n",
    "</div>\n",
    "\n",
    "**Your explanations go here:**\n",
    "\n",
    "It is important to note that accuracy can be misleading when the dataset is imbalanced, meaning that one class has significantly more instances than the other. In such cases, a high accuracy can be achieved by simply predicting the majority class most of the time.\n",
    "\n",
    "Precision (minimising false positives), predicted true, actual false and true: a precision of 0.2857 means that out of all the instances that were predicted as true, only 28.57% of them were actually true. The remaining 71.43% were false positives.\n",
    "\n",
    "Recall (minimising false negatives), predicted true and false, actually true: only 10% of the actual true cases were correctly identified as true by the model. In other words, the model has a low ability to correctly identify positive instances. This means that a large number of true cases are being classified as false negatives.\n",
    "\n",
    "F1-Score (combines precision and recall): An F1 score of 0.15 indicates that the model's performance is relatively poor in terms of both precision and recall. \n",
    "\n",
    "\n",
    "AUC-ROC: The AUC-ROC (Area Under the Receiver Operating Characteristic) score is a metric used to evaluate the performance of a binary classification model. It measures the ability of the model to distinguish between positive and negative instances. \n",
    "An AUC-ROC score of 53 indicates that the model's performance is slightly better than random guessing.\n",
    "\n",
    "<div style=\"width: 100%; height: 1px; background-color: white;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other metrics out there. If you are confused about which one to use, let this be your guide. \n",
    "\n",
    "    Are you predicting probabilities?\n",
    "        Do you need class labels?\n",
    "            Is the minority class more important?\n",
    "                Use Precision-Recall AUC\n",
    "            Are both classes important?\n",
    "                Use ROC AUC\n",
    "        Do you need probabilities?\n",
    "            Use Brier Score and Brier Skill Score\n",
    "    Are you predicting class labels?\n",
    "        Is the minority class more important?\n",
    "            Are False Negatives and False Positives Equally Important?\n",
    "                Use F1-Measure\n",
    "            Are False Negatives More Important?\n",
    "                Use F2-Measure\n",
    "            Are False Positives More Important?\n",
    "                Use F0.5-Measure\n",
    "        Are both classes important?\n",
    "            Do you have < 80%-90% Examples for the Majority Class? \n",
    "                Use Accuracy\n",
    "            Do you have > 80%-90% Examples for the Majority Class? \n",
    "                Use G-Mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 7. Data oversampling\n",
    "\n",
    "\n",
    "We will now take a look at data sampling - oversampling in this section and undersampling in the next section. Over- and under-sampling are techniques used in machine learning to address class imbalance in the dataset, where one class is significantly underrepresented compared to the other class. We will only introduce you to two undersampling and two oversampling techniques and a combination of two sampling techniqes - there exist other, maybe even better, techniques, so don't feel constrained by this notebook and feel free to explore om your own!\n",
    "\n",
    "Also, remember these sampling techniques are not models, but techniques to transform your data, in case of an imbalance. After you have transformed your data, you can apply different (classification) models and examine whether these techniques have yielded you better models. \n",
    "\n",
    "Thus, in the coming sections, we will create a decision tree for each newly data sampled dataset. We will then evaluate their results at the end of this notebook.\n",
    "\n",
    "<img src=\"Data_sampling.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 6 of this notebook, we found that our IBM dataset was imbalanced. More specifically, we saw that only 19% of the employees included in the dataset left the company. To address this issue, we can make use of over-sampling. Over-sampling provides our model with more examples of the minority class. This can help us:\n",
    "- Balance the classes in our dataset\n",
    "- Reduce bias resulting from this imbalance\n",
    "- Potentially improve perforance metrics of the model such as accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Random Oversampling\n",
    "\n",
    "Randomly duplicate examples in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 978, 1: 198})\n",
      "Counter({0: 978, 1: 978})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "ranOveSam = RandomOverSampler(sampling_strategy='minority')\n",
    "X_ro, y_ro = ranOveSam.fit_resample(X_train, y_train)\n",
    "print(Counter(y_ro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new Decision Tree Classifier, fit the model on our newly random oversampled data, and predict on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier _ Random OverSampling\n",
    "DTC_ros = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_ros.fit(X_ro, y_ro)\n",
    "DTC_ros_pred = DTC_ros.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious as to how well this new model performs? We will get back to this in sectionn 10 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 SMOTE Oversampling\n",
    "\n",
    "SMOTE stands for **Synthetic Minority Oversampling TEchnique**. SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample as a point along that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 978, 1: 198})\n",
      "Counter({0: 978, 1: 489})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "smoOveSam = SMOTE(sampling_strategy=0.5)\n",
    "X_S, y_S = smoOveSam.fit_resample(X_train, y_train)\n",
    "print(Counter(y_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier _ SMOTE\n",
    "DTC_SMOTE = DecisionTreeClassifier(random_state=42)\n",
    "DTC_SMOTE.fit(X_S, y_S)\n",
    "DTC_SMOTE_pred = DTC_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious as to how well this new model performs? We will get back to this in sectionn 10 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 8. Data Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 6 of this notebook, we found that our IBM dataset was imbalanced. More specifically, we saw that only 19% of the employees included in the dataset left the company. To address this issue, we first made use of over-sampling (see section above). In this section, we will try out under-sampling.\n",
    "\n",
    "Under-sampling involves reducing the number of instances in the majority class to match the number of instances in the minority class. This can help us:\n",
    "- balance the classes in our dataset\n",
    "- reduce bias resulting from this imbalance\n",
    "- reduce overfitting, especially when the majority class contains a large number of redundant or similar instances\n",
    "- potentially improve perforance metrics of the model such as accuracy, precision and recall\n",
    "<br><br>\n",
    "\n",
    "<img src=\"Data_sampling.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Random Undersampling\n",
    "\n",
    "Randomly delete examples in the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 978, 1: 198})\n",
      "Counter({0: 198, 1: 198})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "ranUndSam = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_ru, y_ru = ranUndSam.fit_resample(X_train, y_train)\n",
    "print(Counter(y_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier _ Random UnderSampling\n",
    "DTC_rus = DecisionTreeClassifier(random_state=42)\n",
    "DTC_rus.fit(X_ru, y_ru)\n",
    "DTC_rus_pred = DTC_rus.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious as to how well this new model performs? We will get back to this in sectionn 10 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 TomekLinks Undersampling\n",
    "\n",
    "A Tomek’s link exists when two samples from different classes are closest neighbors to each other. TomekLink() detects and removes the sample of the majority class or both, since the samples are noisy to the dataset and make it harder to classify observation since instances of both classes are closely present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 978, 1: 198})\n",
      "Counter({0: 887, 1: 198})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "tomLinUndSam = TomekLinks(sampling_strategy='majority')\n",
    "X_T, y_T = tomLinUndSam.fit_resample(X_train, y_train)\n",
    "print(Counter(y_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier _ Tomek UnderSampling\n",
    "DTC_tus = DecisionTreeClassifier(random_state=42)\n",
    "DTC_tus.fit(X_T, y_T)\n",
    "DTC_tus_pred = DTC_tus.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious as to how well this new model performs? We will get back to this in sectionn 10 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 9. Combining Data Sampling techniques\n",
    "\n",
    "You can also combine over- and undersampling techniques for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Combining Oversampling and Undersampling with SMOTE and TomekLinks\n",
    "\n",
    "Luckily, there already exists a function for combining SMOTE and TomekLinks called **SMOTETomek()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 978, 1: 198})\n",
      "Counter({1: 978, 0: 872})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "resample = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "X_ST, y_ST = resample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_ST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier _ SMOTE Tomek\n",
    "DTC_ST = DecisionTreeClassifier(random_state=42)\n",
    "DTC_ST.fit(X_ST, y_ST)\n",
    "DTC_ST_pred = DTC_ST.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious as to how well this new model performs? We will get to that now! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 10. Evaluting Data Sampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[228  27]\n",
      " [ 30   9]]\n",
      "Accuracy: 0.8061224489795918\n",
      "Precision: 0.25\n",
      "Recall: 0.23076923076923078\n",
      "F1-Score: 0.24000000000000002\n",
      "ROC AUC: 0.5624434389140271\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, DTC_ros_pred)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, DTC_ros_pred) \n",
    "# Precision \n",
    "precision = precision_score(y_test, DTC_ros_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_ros_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_ros_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_ros_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "print(\"Confusion Matrix:\"'\\n', cf_matrix)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"ROC AUC:\", roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[204  51]\n",
      " [ 27  12]]\n",
      "Accuracy: 0.7346938775510204\n",
      "Precision: 0.19047619047619047\n",
      "Recall: 0.3076923076923077\n",
      "F1-Score: 0.23529411764705882\n",
      "ROC AUC: 0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, DTC_SMOTE_pred)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, DTC_SMOTE_pred) \n",
    "# Precision \n",
    "precision = precision_score(y_test, DTC_SMOTE_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_SMOTE_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_SMOTE_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_SMOTE_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "print(\"Confusion Matrix:\"'\\n', cf_matrix)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"ROC AUC:\", roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[138 117]\n",
      " [ 13  26]]\n",
      "Accuracy: 0.5578231292517006\n",
      "Precision: 0.18181818181818182\n",
      "Recall: 0.6666666666666666\n",
      "F1-Score: 0.28571428571428575\n",
      "ROC AUC: 0.6039215686274509\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, DTC_rus_pred)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, DTC_rus_pred) \n",
    "# Precision \n",
    "precision = precision_score(y_test, DTC_rus_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_rus_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_rus_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_rus_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "print(\"Confusion Matrix:\"'\\n', cf_matrix)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"ROC AUC:\", roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TomekLinks Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[218  37]\n",
      " [ 30   9]]\n",
      "Accuracy: 0.7721088435374149\n",
      "Precision: 0.1956521739130435\n",
      "Recall: 0.23076923076923078\n",
      "F1-Score: 0.21176470588235294\n",
      "ROC AUC: 0.5428355957767723\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, DTC_tus_pred)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, DTC_tus_pred) \n",
    "# Precision \n",
    "precision = precision_score(y_test, DTC_tus_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_tus_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_tus_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_tus_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "print(\"Confusion Matrix:\"'\\n', cf_matrix)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"ROC AUC:\", roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE & TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[193  62]\n",
      " [ 20  19]]\n",
      "Accuracy: 0.7210884353741497\n",
      "Precision: 0.2345679012345679\n",
      "Recall: 0.48717948717948717\n",
      "F1-Score: 0.31666666666666665\n",
      "ROC AUC: 0.6220211161387632\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, DTC_ST_pred)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, DTC_ST_pred) \n",
    "# Precision \n",
    "precision = precision_score(y_test, DTC_ST_pred) \n",
    "# Recall \n",
    "recall = recall_score(y_test, DTC_ST_pred) \n",
    "# F1-Score \n",
    "f1 = f1_score(y_test, DTC_ST_pred) \n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = roc_curve(y_test, DTC_ST_pred) \n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "print(\"Confusion Matrix:\"'\\n', cf_matrix)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1-Score:\", f1) \n",
    "print(\"ROC AUC:\", roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these score differ drastically from our ordinary decision tree classifier in sections 5-6. Our new decision trees that have been trained on under- and undersampled data may have a worse accuracy than the ordinary decision tree, however they are more correct in term of what and **how** we want to predict something. \n",
    "\n",
    "We don't want a model that **always** guesses 'No attrition' since that is the majority class and just disgards our other class 'Attrition'. Therefore it is safe to say, that all the models we have build in the previous week are not as great as we thought 😄😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=turquoise>EXERCISE 3</font>**\n",
    "Try out some of the over- and undersampling techniques we presented above on models from previous weeks (week 3 - classification and week 4 - ensemble methods). Then examine the results - which model performs the best? Did you have to use oversampling or undersampling? Did you do a combination of both data sampling techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "# Take home messages\n",
    "\n",
    "After finishing this notebook, you should:\n",
    "- be able to perform - and preferably also explain (!) - the evaluation metrices for classification presented in this notebook\n",
    "- be able to perform data over- and under-sampling and explain when and why this is useful\n",
    "- evalute your models based onm more than just accuracy score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
