{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Pink>A step-by-step guide to getting started with modelling using your own dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes you through all the steps, you need to perform, when you start working with your own dataset. However, be aware that you will most likely go back and forth between some of the steps or reiterate the whole cycle one more time after making and evaluating your first model(s). Thus, *<font color=Orchid><b>although this notebook is a linear step-by-step guide, the process of creating a classifiation model is NOT linear</b></font>*, i.e., you should be going back and forth between the steps. For instance, having trained and evaluated a model will likely make you want to go back and train it again on different features or with different parameters.\n",
    "\n",
    "The steps below are partly inspired by the stages of the CRISP-DM process model for data science ('The CRoss Industry Standard Process for Data Mining').<br>\n",
    "\n",
    "The steps are as follows:\n",
    "<ol>\n",
    "    <li><b><font color=Orchid>Import your dataset and libraries</font></b></li>\n",
    "    <li><b><font color=Orchid>Perform exploratory data analysis of your dataset</font></b> ('Data Understanding')</li>\n",
    "    <li><b><font color=Orchid>Clean your dataset</font></b> ('Data Preparation')</li>\n",
    "    <li><b><font color=Orchid>Train one or more classification models</font></b> ('Modeling')</li>\n",
    "    <li><b><font color=Orchid>Evaluate your model(s)</font></b> ('Evaluation')</li>\n",
    "</ol>\n",
    "\n",
    "**Remember, you can find all the code, you need to use in each step, in the relevant exercise notebooks!**\n",
    "\n",
    "**The CRISP-DM process model:** <br>\n",
    "\n",
    "<img src=\"crisp-dm.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dataset and libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you import you dataset as well as the libraries you plan on using, i.e., pandas, sklearn etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you examine your dataset performing what is called \"exploratory data analysis\". For instance, you likely want to know:\n",
    "- which columns/features your dataset contains\n",
    "- the data type of the features\n",
    "- whether there are any missing values\n",
    "- whether there are any outliers\n",
    "- whether your dataset is balanced when it comes to your target feature\n",
    "- how other features are distributed\n",
    "- how your target variable correlates with various features in the dataset, i.e., making a correlation matrix/heatmap (this might require you to clean the dataset first, see step 3)\n",
    "\n",
    "N.B.: You will likely be going back and forth between exploring and cleaning the dataset.\n",
    "\n",
    "Hint: the notebooks <font color=Orchid>\"BDP_Basics\" and \"BDP_EDA\"</font> will be your friend here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is based on your findings in step 2. Thus, cleaning the dataset may entail:\n",
    "- handling missing values\n",
    "- handling outliers\n",
    "- handling nominal data (i.e., data which is nut numerical)\n",
    "\n",
    "After the initial cleaning, you will likely go back to step 2 and make a correlation matrix.\n",
    "\n",
    "Hint: the notebooks <font color=Orchid>\"BDP_Basics\" and \"BDP_EDA\"</font> will be your friend here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling can be done by following these steps. However, be aware that **<font color=Orchid>modeling is NOT a linear process, but an iterative process</font>**, i.e., you will very likely have to go back and forth between the steps below.\n",
    "\n",
    "- 4.1. Select variables to use in your model\n",
    "- 4.2 Split your data into test and train data\n",
    "- 4.3 Apply datasampling (if your dataset is unbalanced)\n",
    "- 4.4 Select model type\n",
    "- 4.5 Select parameters for your model\n",
    "- 4.6 Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Start by selecting the variables you want to use in your model\n",
    "\n",
    "Regardles which model you plan on using, you need to start by:\n",
    "- selecting the **<font color=\"Orchid\">target/dependent variable ('y')</font>**\n",
    "- selecting the **<font color=\"Orchid\">features/independent variables</font>** you want to use for your prediction ('X')\n",
    "\n",
    "The features you choose can depend on one or more of the following:\n",
    "- you own hypotheses/existing literature \n",
    "- findings from your data exploration\n",
    "- findings and insights gained while modeling (you will likely go back and forth in your modeling process, trying out various features and parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Next, split your data into test and train data\n",
    "\n",
    "Remember - if you plan on using KNN for classification, you need to scale your data before training/fitting the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 For unbalanced datasets, you can now apply data sampling techniques\n",
    "\n",
    "If your data is not balanced (i.e., there is an unequal distribution of observations belonging to each of the classes in your target variable), you can balance the classes using over- or undersampling.\n",
    "\n",
    "Over-sampling techniques:\n",
    "- random oversampling\n",
    "- SMOTE oversampling (synthethic oversampling)\n",
    "\n",
    "Undersampling techniques:\n",
    "- random undersampling\n",
    "- TomekLinks undersampling\n",
    "\n",
    "Combining over- and undersampling:\n",
    "- SMOTETomek\n",
    "\n",
    "<br>\n",
    "<img src=\"../week5/Data_sampling.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Select the type of model you want to try out\n",
    "\n",
    "Now, you are ready to do some modelling!\n",
    "\n",
    "You can do classification modeling using a *single* model or a mix of *several* models (i.e., an ensemble)\n",
    "\n",
    "We have looked at the following *single* classification models:\n",
    "- Decision trees\n",
    "- KNN\n",
    "\n",
    "We have looked at the following *ensemble models* for classification:\n",
    "- Bagging (including random forests)\n",
    "- Boosting\n",
    "- Ensemble voting\n",
    "\n",
    "<br>\n",
    "<img src=\"../week4/Bagging_Boosting.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Select parameters for your model (hyperparameter tuning)\n",
    "\n",
    "When building/training a classification model, you can provide it with various *parameters*.\n",
    "\n",
    "For **<font color=\"Orchid\">decision trees</font>**, relevant parameters include:\n",
    "- max_depth\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "\n",
    "For **<font color=\"Orchid\">KNN</font>**, we have looked at the parameter:\n",
    "- k (number of neighbours)\n",
    "\n",
    "The performance of your model depend on these parameters. To identify the most optimal values of these parameters, you perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Training your model\n",
    "\n",
    "After having decided on:\n",
    "- which model you want to try out\n",
    "- whether you need to apply samling methods\n",
    "- optimal parameters\n",
    "\n",
    "... you fit/train yout model on your training data. Again, remember to scale the data, if you are using KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluating your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained a model, you now want to assess its performance.\n",
    "\n",
    "You can assess the performance using various methods and metrics:\n",
    "- accuracy\n",
    "- confusion matrix\n",
    "- recall\n",
    "- precision\n",
    "- specificity\n",
    "- AUC-ROC\n",
    "- F1\n",
    "\n",
    "**<font color=Orchid>Having evaluated your model, you will likely go back to previous stages, such as 'Data Understanding' and 'Modeling', training new models based on your findings so far.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
